---
category: philosophy
date: 2021-05-25 08:30:00
image: /assets/images/newsletter/issue_20/stephen-leonardi-XqzLUKzg49c-unsplash.jpeg
layout: post
link: https://www.project-syndicate.org/onpoint/how-to-think-about-existential-and-immediate-risks-by-daron-acemoglu-2021-05
story_number: 1
title: ARGH! AI is going to kill us all!
word_count: 2,454
---


The dinosaurs were killed-off by an asteroid. We'll probably be killed-off by ourselves.

There is a burgeoning tradition of prophecies by clever rich white men about the long term dangers of 'super-intelligent' AI. A new [book](https://www.amazon.co.uk/dp/B082SXGJYC/) on the topic has now been added by  Oxford philosopher Toby Ord and nicely [reviewed](https://www.project-syndicate.org/onpoint/how-to-think-about-existential-and-immediate-risks-by-daron-acemoglu-2021-05) by Daron Acemoglu.

The idea goes like this: we've power not wisdom, we've developed technology without the ability to control it. We should minimise existential risk whatever the cost. We should focus a large amount of current resources on avoiding the fate of the dinosaurs. The greatest threat is AI.

I don't buy it. Worrying about super intelligent AI taking over is (as Andrew Ng said) like worrying about overpopulation on Mars. We're not there yet.

What we should be worrying about is the impact existing AI + human chimeras and their corporate bodies are having on the world today. Inequality, environmental damage, misinformation and control are all big present problems that would be more fruitful to focus on. Initiatives such as the EU's proposed AI regulation are likely to have more positive impact than philosophical warbling (much as I enjoy philosophical warbling).

üõéÔ∏è **Why this matters:** AI already runs the world.