---
category: philosophy
date: 2021-06-22 08:30:00
image: /assets/images/newsletter/issue_21/andrea-lightfoot-Pj6fYNRzRT0-unsplash.jpeg
layout: post
link: https://www.arxiv-vanity.com/papers/2007.09560/
story_number: 4
title: Do algorithms dream of simulated sheep?
word_count: 12,835
---
Dreams are a way to stop the brain overfitting, according to a new theory.

Overfitting is a concept in machine learning where a model works well on a training dataset but fails to generalise to new, unseen data. Many approaches have been taken to reduce overfitting including weight regularisation, dropout,  noise addition and early stopping. These are part of the standard ML toolkit.

A new [paper](https://www.arxiv-vanity.com/papers/2007.09560/) proposes that the purpose of dreaming in humans and other animals is to stop the brain from overfitting - this is known as the Overfitted Brain Hypothesis. Dreams effectively generate data outside of our usual training set to push the limits of our perceptual models. If you look at the same computer monitor every day, everything might start to look like a monitor. Dreams mix things up a bit.

üõéÔ∏è **Why this matters:** It's a nice theory, I've no idea if it's true. I'll sleep on it.