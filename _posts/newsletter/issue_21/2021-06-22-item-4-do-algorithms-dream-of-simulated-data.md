---
category: philosophy
date: 2021-06-22 08:30:00
image: /assets/images/newsletter/issue_21/andrea-lightfoot-Pj6fYNRzRT0-unsplash.jpeg
layout: post
link: https://www.arxiv-vanity.com/papers/2007.09560/
story_number: 4
title: Do algorithms dream of simulated data?
word_count: 12,835
---

Dreams are a way to stop the brain overfitting, according to a new theory.

Overfitting is a concept in machine learning where a model works well on a training dataset but fails to generalise to new applications. This is often seen when a model performs very well on a training set but less well on a test set. Many approaches have been taken to reduce overfitting including weight regularisation, dropout,  noise addition and early stopping. These are part of the standard ML toolkit.

A new [paper](https://www.arxiv-vanity.com/papers/2007.09560/) proposes that the purpose of dreaming in humans and other animals is too stop the brain from overfitting - this is know as the Overfitted Brain Hypothesis. Dreams effectively generate data outside of our usual training set to push the limits of our perceptual models.

üõéÔ∏è **Why this matters:** It's a nice theory.

