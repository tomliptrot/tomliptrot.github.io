---
category: null
date: 2020-12-08 08:30:00
image: /assets/images/books-1245690_1280.jpg
layout: post
link: http://ai.stanford.edu/blog/learning-from-language/
story_number: 1
title: Learning like people
word_count: '750'
---

Up until recently models learnt using labelled data but humans learnt using language. This is starting to change.

It is starting to become possible to describe tasks using natural language so that the machines can learn. This allows much faster learning using less data. Which is similar to how humans operate. This opens the possibility of interacting with and trading computers in exactly the same way we do with humans. Models like GPT-2 and 3 and BERT have made this possible.

This research is similar to the [PET](https://github.com/timoschick/pet) paper linked to a couple of weeks ago and is a really exciting avenue of research. As the authors say:

> "We envision a future where in order to solve a machine learning task, we no longer have to collect a large labeled dataset, but instead interact naturally and expressively with a model in the same way that humans have interacted with each other for millenniaâ€”*through language*."